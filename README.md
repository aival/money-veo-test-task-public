# moneyveo

Задача - разработать инструмент, который позволяет решить задачу  бинарной классификации.
 
Мы предоставляем вам 2 файла (тренировочная и проверочная часть).
- Id - уникальный идентификатор события в выборке, 
- pXXX – значение параметра по событию,
- Status - целевая переменная(класс), заполнена только для тренировочной части выборки.
 
Трактовать параметры в плане  категорий и/или непрерывных характеристик можете по вашему усмотрению.

Результат выполнения задания обязательно должен состоять из идентификатора события и вероятности принадлежности к классу (по всем событиям, включая тестовую часть), а также отчета, описывающего процесс построения и результаты.


### Процесс выполнения

1. Загрузил данные в DataFrame.
2. Оценил выборку по типам данных (непрерывные, целочисленные, булевые, строковые).
3. Проверил пропущенные значения, нелогичные значения (например код номера один был "6", вместо двухзначного кода).
4. Пропущенные значения оставил таковыми - по связи с целевой - новую категорию лучше ввести (а дальше она автоматом выделиться DictVectorizer'ом - что-то типа защищенного от новых значений категориальных переменных кодировщик и бинаризатор переменных)
5. С кодом номера телефона не мудрил - после бинаризации убирал те категории у которых дисперсия меньше (98%)*(1-98%)
6. Посмотрел на целочисленные фичи с небольшим кол-вом возможных значений. Посмтроил их гистограммы по целевой -> отобрал те которые явно не упорядочены и имели до 25 вариантов значений -> пустил на бинаризацию и отсечение по мальнькой дисперсии.
7. С категориальными строковыми и булевскими поступил аналогично.
8. Непрерывные переменные (включая целочисленные, которые не отнес к категориальным) пронормировал робустным QuantileTransformer к нормальному распределению - желательно нормировать до PCA
9. Написал трансформер, который исключает фичи с корреляцией от 90%.
10. Тестово преобразовал данные и посмотрел на VIF, дополнительно включал единичный вектор, т.к. по умолчанию пакет без сдвига коэффициенты линейной регрессии берет (теперь только 9 переменных больше 10 имеют значение - до 20-25 проде бы было, что неплохо, а после PCA все VIF-значения == 1).
11. Для балансировки выборки синтезировал точки меньшего класса методом SMOTE.
12. Теперь применяем PCA: поигравшись остановился на том, чтобы новое подпространство фич определялось по Minka’s MLE (хотя 80% влияния фич по собственным векторам где-то у 60-80 переменных было)
13. (Опускаем момент где я счетно пытался подобрать фдерные функции перевода пространства - на таком объеме выборок те методы, которым хватает памяти, сильно переобучаются - очень чуствительны к размеру выборки обучающей)
14. Добавил в pipeline логит-регрессию.
15. Составил рандомизированный поиск значений гиперпараметра C (отбирал по ROC_AUC; брал всего 3-фолда, но хватило как увидим).
16. Определил значение C=29. Построил значения оценок качества (Recall, Precision, Accuracy, ROC_AUC, matthews correlation coefficient, F1). Качество нормальное, разброс небольшой между обучающей и проверочной, но еще посмотрим.
17. Построилкривую обучения в зависимоти от размера выборки на обучение. Очень неплоха. Небольшое расстояние, сходятся одинаково, разброс незначительный.
18. Для оценки кросс-валидации (особенно учитывая что только 3-фолда было) запустил тест устойчивости к перестановкам значений целевой переменной. Результат получился максимально хорош, который можно было достичь с 10ю запусками перестановок.
19. Так как настраивал только один гиперпараметр, то можно легко посмотреть на зависимоть оценочных параметров от значения гиперпараметра регуляризации логитки - не сильно изменялись значения различных оценок при различных C.
20. Теперь обучим на всей выборке, спрогнозируем тестовый набор (20% от первоначального фиксировал) и помотрим еще раз на ROC_AUC и отчет клиссификации:
AUC: 0.8570888875

             precision    recall  f1-score   support
          0       0.98      0.76      0.86     61285
          1       0.20      0.79      0.32      4689
avg / total       0.92      0.77      0.82     65974

21. Результат никуда не перекосился, даже немногоулучшился  после обучения на всем наборе данных, что ожидаемо (оценочный AUC на тестовом при обучении только на обучающем наборе был AUC: 0.8505)
22. Финал: сохраняем обученную модель. Загружаем модель (проверим, что все ок), загружаем тестовый набор и предсказываем вероятности класса 1 и 0 (получаем 0,1 и меняем местами для удобства). Выгружаем в CSV Id события, вероятность принадлежности к классу/Status=1, вероятность принадлежности к классу/Status=0.

### ОБНОВЛЕНИЕ
1. [Logit_and_RF](mvt/01_logit_n_rf.ipynb) Нашел оптимальные гиперпараметры для Random Forest по MCC (Matthews correlation coefficient) - по данной метрике лучше сходится без переобучения. Достаточно было подстроить гипперпараметр min_impurity_decrease.
2. [CL](mvt/03_calibration_trainee.ipynb) Откалибровал Random Forest в части вероятностей предсказанного класса делением на 5 наборов (калибровка немного улучшила результат + важна для дальнейшего использования ансамбля с усреднением предсказанной вероятности по всем классификаторам).
3. [GB](mvt/02_gb.ipynb) Проделал п. 1 и п. 2 для GradientBoosting. У него основными гиперпараметрами к настройке были глубина деревьев и минимальная доля образцов в листе. В калибровке использовал деление на 8-поднаборов.
4. Оптимизировал логитку не по ROC_AUC метрике, а по MCC-метрике.
5. [RES](mvt/00_vc_res.ipynb) На обучающей выборке (поделенной на 80% обучающей 20% тестовой) получились следующие результаты (немного улучшились по многим метрикам в сравнении с обособленным классификатором):

#TRAIN VC#  
[train_res_csv_file](mvt/src/Train_Sample_Res_vc_lrg_12_15.csv)  
1. AUC: 0.8525058080837687
2. F1: 0.36579831170009985
3. MCC: 0.32072848774487434
4. KS: D=0.06659845771992645, p-value=3.0505415287114118e-102
5. Log Loss: 0.3095794370492794

#TEST VC#  
[test_res_csv_file](mvt/src/Test_Sample_Res_vc_lrg_12_15.csv)  
1. AUC: 0.8459309531666601
2. F1: 0.3608065086664308
3. MCC: 0.3163768503080902
4. KS: D=0.07207275483137554, p-value=2.78583904998641e-30
5. Log Loss: 0.31921899992189595

             precision    recall  f1-score   support

          0       0.96      0.89      0.92     12257
          1       0.27      0.54      0.36       938

avg / total       0.91      0.86      0.88     13195
